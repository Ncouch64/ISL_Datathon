{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "23-12-23 14:12:03 - Directory C:\\Users\\Funniest Valentine/.deepface created\n",
      "23-12-23 14:12:03 - Directory C:\\Users\\Funniest Valentine/.deepface/weights created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataframe, setting input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment = pd.DataFrame(columns = ['filename', 'gender', 'race', 'age', 'emotion'])\n",
    "input = 'faceimages'\n",
    "images = os.listdir(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepface Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.92it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.93it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.64it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.73it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.14it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.73it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.60it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.74it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.27it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.32it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.61it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.10it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.38it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.74it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.12it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.04it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.05it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.06it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.98it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.72it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.72it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.76it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.73it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.16it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.51it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.62it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.24it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.03it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.73it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.41it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.57it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.45it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.27it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.44it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.52it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.52it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.55it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.34it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.70it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.21it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.11it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.16it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.48it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.16it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.13it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.78it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.93it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.59it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.01it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.92it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.25it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.09it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.49it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.49it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.36it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.09it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.84it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.07it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.80it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.14it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.08it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.62it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.71it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.67it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.15it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.80it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.62it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.68it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.59it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.52it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.40it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.60it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.64it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.59it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.38it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.57it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.69it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.58it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.36it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.44it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.20it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.49it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.35it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.40it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.54it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.44it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  6.54it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.69it/s]\n",
      "Action: race:  25%|██▌       | 1/4 [00:00<00:00,  4.25it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m----> 2\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Gender filler\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     gender \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\deepface\\DeepFace.py:390\u001b[0m, in \u001b[0;36manalyze\u001b[1;34m(img_path, actions, enforce_detection, detector_backend, align, silent)\u001b[0m\n\u001b[0;32m    387\u001b[0m     obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdominant_gender\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Gender\u001b[38;5;241m.\u001b[39mlabels[np\u001b[38;5;241m.\u001b[39margmax(gender_predictions)]\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 390\u001b[0m     race_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, :]\n\u001b[0;32m    391\u001b[0m     sum_of_predictions \u001b[38;5;241m=\u001b[39m race_predictions\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    393\u001b[0m     obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\keras\\src\\engine\\training.py:2620\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2617\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2618\u001b[0m         )\n\u001b[1;32m-> 2620\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:370\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    366\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mwith_options(options)\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1240\u001b[0m, in \u001b[0;36mDatasetV2.prefetch\u001b[1;34m(self, buffer_size, name)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprefetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer_size, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \n\u001b[0;32m   1215\u001b[0m \u001b[38;5;124;03m  Most dataset input pipelines should end with a call to `prefetch`. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprefetch_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1241\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:28\u001b[0m, in \u001b[0;36m_prefetch\u001b[1;34m(input_dataset, buffer_size, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m input_dataset\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_PrefetchDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:46\u001b[0m, in \u001b[0;36m_PrefetchDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, slack_period, name)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# We colocate the prefetch dataset with its input as this collocation only\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# happens automatically in graph mode.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m---> 46\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43mslack_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslack_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Funniest Valentine\\ISL\\Datathon\\Datathon_12_23_2023\\datathon_1\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:5933\u001b[0m, in \u001b[0;36mprefetch_dataset\u001b[1;34m(input_dataset, buffer_size, output_types, output_shapes, slack_period, legacy_autotune, buffer_size_min, metadata, name)\u001b[0m\n\u001b[0;32m   5931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   5932\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5933\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5934\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrefetchDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5935\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5936\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslack_period\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslack_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlegacy_autotune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy_autotune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5937\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuffer_size_min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   5939\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    predictions = DeepFace.analyze(img_path = os.path.join(input, img),\n",
    "                            actions = ['gender', 'race', 'age', 'emotion'], \n",
    "                            enforce_detection=False)\n",
    "    \n",
    "    # Gender filler\n",
    "    gender = predictions[0]['gender']\n",
    "    gender_accepted = .80\n",
    "    dominant_gender, gender_confidence = max(gender.items(), key = lambda item: item[1])\n",
    "    if gender_confidence < gender_accepted:\n",
    "        gender = 'Unknown'\n",
    "    else:\n",
    "        gender = dominant_gender\n",
    "\n",
    "    # Race filler\n",
    "    min_acc_confindent = 0.5\n",
    "    race = predictions[0]['race']\n",
    "    dominant_race, race_confidence = max(race.items(), key = lambda item: item[1])\n",
    "    if race_confidence < min_acc_confindent:\n",
    "        race = 'Unknown'\n",
    "    else:\n",
    "        race = dominant_race\n",
    "    \n",
    "    # Age filler\n",
    "    age = predictions[0]['age']\n",
    "    if np.isnan(age) or age == 0:\n",
    "        age = -1\n",
    "\n",
    "    # Not part of the assignment but I wanted to see how well this works\n",
    "    emotion = predictions[0]['emotion']\n",
    "    dominant_emotion, emotion_confidence = max(emotion.items(), key = lambda item: item[1])\n",
    "    if emotion_confidence < min_acc_confindent:\n",
    "        emotion = 'Unknown'\n",
    "    else:\n",
    "        emotion = dominant_emotion\n",
    "    \n",
    "    # Creating dictionary for adding a new row to the existing dataframe\n",
    "    result_row = {'filename': img, 'gender': gender, 'race': race, 'age': age, 'emotion': emotion}\n",
    "\n",
    "    # concatenating the new row to the dataframe \n",
    "    assignment = pd.concat([assignment, pd.DataFrame([result_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment.to_csv('assignment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
